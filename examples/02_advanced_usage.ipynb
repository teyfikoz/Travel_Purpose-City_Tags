{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TravelPurpose Advanced Usage\n",
    "\n",
    "Advanced features including custom ontologies, pipeline execution, and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from travelpurpose import predict_purpose, tags\n",
    "from travelpurpose.utils.io import load_ontology, load_cities_data\n",
    "from travelpurpose.utils.scoring import calculate_tag_weights, aggregate_scores_by_category\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Tag Sources and Weights\n",
    "\n",
    "Examine how tags from different sources are weighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tags for a city\n",
    "city_tags = tags(\"Paris\", use_cache=False)\n",
    "\n",
    "# Calculate weights\n",
    "tag_weights = calculate_tag_weights(city_tags)\n",
    "\n",
    "# Show top weighted tags\n",
    "sorted_tags = sorted(tag_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 15 weighted tags:\")\n",
    "for tag, weight in sorted_tags[:15]:\n",
    "    print(f\"{tag:25} | Weight: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Tag Source Weights\n",
    "\n",
    "Customize weights for different sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom weights\n",
    "custom_weights = {\n",
    "    \"wikidata\": 2.0,  # Trust Wikidata more\n",
    "    \"booking\": 1.2,\n",
    "    \"agoda\": 1.0,\n",
    "    \"trivago\": 0.8,\n",
    "}\n",
    "\n",
    "# Recalculate with custom weights\n",
    "custom_tag_weights = calculate_tag_weights(city_tags, source_weights=custom_weights)\n",
    "\n",
    "print(\"Comparison of default vs custom weights:\")\n",
    "for tag in sorted_tags[:10]:\n",
    "    default_w = tag_weights.get(tag[0], 0)\n",
    "    custom_w = custom_tag_weights.get(tag[0], 0)\n",
    "    print(f\"{tag[0]:20} | Default: {default_w:.2f} | Custom: {custom_w:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Ontology Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = load_ontology()\n",
    "\n",
    "print(\"Ontology Statistics:\")\n",
    "print(f\"Main Categories: {len(ontology['main_categories'])}\")\n",
    "print(f\"Total Subcategories: {sum(len(subs) for subs in ontology['subcategories'].values())}\")\n",
    "print(f\"Tag Mappings: {len(ontology['tag_mappings'])}\")\n",
    "\n",
    "# Show category hierarchy\n",
    "print(\"\\nCategory Hierarchy:\")\n",
    "for main_cat in ontology['main_categories'][:5]:\n",
    "    subs = ontology['subcategories'].get(main_cat, [])\n",
    "    print(f\"\\n{main_cat} ({len(subs)} subcategories):\")\n",
    "    for sub in subs[:3]:\n",
    "        print(f\"  - {sub}\")\n",
    "    if len(subs) > 3:\n",
    "        print(f\"  ... and {len(subs)-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyzing Tag-to-Category Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate tags to categories\n",
    "tag_mappings = ontology.get('tag_mappings', {})\n",
    "main_scores, sub_scores = aggregate_scores_by_category(tag_weights, tag_mappings)\n",
    "\n",
    "print(\"Main Category Scores:\")\n",
    "for cat, score in sorted(main_scores.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{cat:25} | Score: {score:.3f}\")\n",
    "\n",
    "print(\"\\nTop Subcategory Scores:\")\n",
    "for cat, score in sorted(sub_scores.items(), key=lambda x: x[1], reverse=True)[:8]:\n",
    "    print(f\"{cat:25} | Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Analysis\n",
    "\n",
    "Analyze the cities dataset (if available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cities dataset\n",
    "df = load_cities_data()\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"Total cities: {len(df)}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    print(f\"\\nSample:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No dataset available. Run the pipeline to generate data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running the Data Pipeline\n",
    "\n",
    "Execute the data pipeline programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This will make network requests. Use sample_size to limit.\n",
    "# Uncomment to run:\n",
    "\n",
    "# from scripts.pipeline import run_pipeline\n",
    "# \n",
    "# run_pipeline(\n",
    "#     nbd_path=None,\n",
    "#     output_dir=\"./output\",\n",
    "#     min_population=200000,\n",
    "#     sample_size=5  # Small sample for testing\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Classification Logic\n",
    "\n",
    "Build your own classifier using the library components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from travelpurpose.utils.normalize import normalize_tag\n",
    "from travelpurpose.utils.scoring import normalize_scores, select_top_labels\n",
    "\n",
    "def custom_classifier(city_name: str, min_confidence: float = 0.20):\n",
    "    \"\"\"\n",
    "    Custom classifier with stricter confidence threshold.\n",
    "    \"\"\"\n",
    "    # Get tags\n",
    "    city_tags = tags(city_name, use_cache=True)\n",
    "    \n",
    "    if not city_tags:\n",
    "        return None\n",
    "    \n",
    "    # Calculate weights\n",
    "    tag_weights = calculate_tag_weights(city_tags)\n",
    "    \n",
    "    # Aggregate\n",
    "    ontology = load_ontology()\n",
    "    main_scores, sub_scores = aggregate_scores_by_category(\n",
    "        tag_weights, \n",
    "        ontology['tag_mappings']\n",
    "    )\n",
    "    \n",
    "    # Normalize\n",
    "    main_scores = normalize_scores(main_scores)\n",
    "    sub_scores = normalize_scores(sub_scores)\n",
    "    \n",
    "    # Select with custom threshold\n",
    "    top_main = select_top_labels(main_scores, threshold=min_confidence, max_labels=3)\n",
    "    top_sub = select_top_labels(sub_scores, threshold=min_confidence*0.8, max_labels=5)\n",
    "    \n",
    "    return {\n",
    "        'main': [label for label, _ in top_main],\n",
    "        'sub': [label for label, _ in top_sub],\n",
    "        'main_scores': dict(top_main),\n",
    "        'sub_scores': dict(top_sub)\n",
    "    }\n",
    "\n",
    "# Test custom classifier\n",
    "result = custom_classifier(\"Dubai\", min_confidence=0.25)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparative Analysis\n",
    "\n",
    "Compare classifications across similar cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similar cities\n",
    "city_groups = {\n",
    "    'Beach Resorts': ['Antalya', 'Cancun', 'Phuket', 'Maldives'],\n",
    "    'Business Hubs': ['Singapore', 'Frankfurt', 'Dubai', 'Hong Kong'],\n",
    "    'Cultural Cities': ['Rome', 'Athens', 'Kyoto', 'Jerusalem']\n",
    "}\n",
    "\n",
    "for group_name, cities in city_groups.items():\n",
    "    print(f\"\\n{group_name}:\")\n",
    "    for city in cities:\n",
    "        result = predict_purpose(city, use_cache=True)\n",
    "        main_cats = ', '.join(result['main'][:2])\n",
    "        print(f\"  {city:15} | {main_cats:40} | Conf: {result['confidence']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Custom weighting of tag sources\n",
    "- Ontology exploration and customization\n",
    "- Building custom classifiers\n",
    "- Dataset analysis\n",
    "- Comparative city analysis\n",
    "\n",
    "For more information, see the [documentation](https://github.com/teyfikoz/Travel_Purpose-City_Tags)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
